# retriever_test.py (LLM ì‘ë‹µ í¬í•¨)

from dotenv import load_dotenv
load_dotenv(dotenv_path="/data/ephemeral/home/QA/.env")

from langchain_community.vectorstores import FAISS
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain.chains import RetrievalQA

# 1. ì—…ìŠ¤í…Œì´ì§€ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
embedding = UpstageEmbeddings(model="solar-embedding-1-large")

# 2. FAISS ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
vectorstore = FAISS.load_local(
    folder_path="/data/ephemeral/home/QA/faiss_store",
    embeddings=embedding,
    allow_dangerous_deserialization=True
)

# 3. LangChain ë¦¬íŠ¸ë¦¬ë²„ ê°ì²´ ìƒì„±
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# 4. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
query = input("\n ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
docs = retriever.get_relevant_documents(query)

# 5. ìœ ì‚¬ ë¬¸ë‹¨ ì¶œë ¥
for i, doc in enumerate(docs, 1):
    print(f"\nğŸ” ê²°ê³¼ {i}\n{doc.page_content}")

# 6. LLM QA ì²´ì¸ ìƒì„± ë° ì‘ë‹µ ì¶œë ¥
llm = ChatUpstage()
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

qa_response = qa_chain.invoke({"query": query})

print("\n LLM ì‘ë‹µ:")
print(qa_response["result"])
import os
print("ğŸ” API Key:", os.getenv("UPSTAGE_API_KEY"))